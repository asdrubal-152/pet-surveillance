{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic segmentation test\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** [rodoart](https://github.com/rodoart/)<br>\n",
    "**Date created:** 2020/07/19<br>\n",
    "**Last modified:** 2021/07/19<br>\n",
    "**Description:** \n",
    "Example of a network to create bounding boxes and label, based on [Divam Gupta (2019)](https://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html)\n",
    "\n",
    "# A Beginner's guide to Deep Learning based Semantic Segmentation using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path config\n",
    "\n",
    "If you want the files to be copied to another folder within the same machine you are working on, by a source path other than remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_SLUG = 'vigilancia_mascotas'\n",
    "NAME = 'semantic_segmentation_test'\n",
    "NUMBER = '0.0'\n",
    "\n",
    "\n",
    "NOTEBOOK_NAME = f'{NUMBER}-{PROJECT_SLUG}-{NAME}.ipynb'\n",
    "\n",
    "# COLAB\n",
    "#DRIVE_MOUNT = '/drive'\n",
    "#REMOTE_PATH = f'{DRIVE_MOUNT}/MyDrive/proyects/{PROJECT_SLUG}'\n",
    "#LOCAL_PATH = '.'\n",
    "#NOTEBOOK_PATH = f'{DRIVE_MOUNT}/MyDrive/Colab Notebooks/{NOTEBOOK_NAME}'\n",
    "\n",
    "# LOCAL\n",
    "REMOTE_PATH = '..'\n",
    "LOCAL_PATH = '..'\n",
    "DRIVE_MOUNT = ''\n",
    "NOTEBOOK_PATH = f'G:\\\\Mi unidad\\\\Colab Notebooks\\\\{NOTEBOOK_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DRIVE_MOUNT:\n",
    "    from google.colab import drive\n",
    "    drive.mount(DRIVE_MOUNT)\n",
    "    to_remote = True\n",
    "else:\n",
    "    to_remote = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# It depends on where the library that comes with this package is stored.\n",
    "sys.path.append(REMOTE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vigilancia_mascotas.utils.paths \\\n",
    "    import make_remote_copy_of_workspace_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir, update_from_remote, update_to_remote, update_notebook = \\\n",
    "    make_remote_copy_of_workspace_functions(\n",
    "        local_path=LOCAL_PATH,\n",
    "        remote_path=REMOTE_PATH,\n",
    "        notebook_path = NOTEBOOK_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We will be using Keras for building and training the segmentation models. First, install `keras_segmentation` which contains all the utilities required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The first step in training our segmentation model is to prepare the dataset. We would need the input RGB images and the corresponding segmentation images. If you want to make your own dataset, a tool like [labelme](https://github.com/wkentaro/labelme) or [GIMP](https://www.gimp.org/) can be used to manually generate the ground truth segmentation masks.\n",
    "\n",
    "Assign each class a unique ID. In the segmentation images, the pixel value should denote the class ID of the corresponding pixel. This is a common format used by most of the datasets and `keras_segmentation`. For the segmentation maps, do not use the `jpg` format as `jpg` is lossy and the pixel values might change. Use `bmp` or png format instead. And of course, the size of the input image and the segmentation image should be the same.\n",
    "\n",
    "In the following example, pixel (0,0) is labeled as class 2, pixel (3,4) is labeled as class 1 and rest of the pixels are labeled as class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_1_path = local_dir('data', 'processed', 'semantic_segmentation', \n",
    "                       'ann_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(ann_1_path.parent, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ann_img = np.zeros((30,30,3)).astype('uint8')\n",
    "ann_img[ 3 , 4 ] = 1 # this would set the label of pixel 3,4 as 1\n",
    "ann_img[ 0 , 0 ] = 2 # this would set the label of pixel 0,0 as 2\n",
    "\n",
    "cv2.imwrite(str(ann_1_path), ann_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the segmentation images, place them in the training/testing folder. Make separate folders for input images and the segmentation images. The file name of the input image and the corresponding segmentation image should be the same.\n",
    "\n",
    "Refer to the format below :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dataset/\n",
    "\ttrain_images/\n",
    "\t\t- img0001.png\n",
    "\t\t- img0002.png\n",
    "\t\t- img0003.png\n",
    "\ttrain_segmentation/\n",
    "\t\t- img0001.png\n",
    "\t\t- img0002.png\n",
    "\t\t- img0003.png\n",
    "\tval_images/\n",
    "\t\t- img0004.png\n",
    "\t\t- img0005.png\n",
    "\t\t- img0006.png\n",
    "\tval_segmentation/\n",
    "\t\t- img0004.png\n",
    "\t\t- img0005.png\n",
    "\t\t- img0006.png\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and unzip the example dataset\n",
    "\n",
    "You can refer to a sample dataset [here](https://github.com/divamgupta/image-segmentation-keras/tree/master/test/example_dataset).\n",
    "\n",
    "\n",
    "For this tutorial we would be using a data-set which is already prepared. You can download it from [here](https://drive.google.com/file/d/0B0d9ZiqAgFkiOHR1NTJhWVJMNEU/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '0B0d9ZiqAgFkiOHR1NTJhWVJMNEU'\n",
    "zip_path = local_dir('tmp', 'semantic_segmentation', 'dataset1.zip')\n",
    "dataset_path = local_dir('data', 'raw', 'semantic_segmentation')\n",
    "\n",
    "makedirs(zip_path.parent, exist_ok=True)\n",
    "makedirs(dataset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_path.is_dir() and not zip_path.is_file():\n",
    "    url_gdown = f'https://drive.google.com/u/0/uc?id={file_id}'\n",
    "    gdown.download(url_gdown, str(zip_path), quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "if not dataset_path.is_dir():\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_path = dataset_path.joinpath('dataset1')\n",
    "\n",
    "train_images_path = dataset1_path.joinpath('train_images')\n",
    "train_segmentation_path = dataset1_path.joinpath('train_segmentation')\n",
    "\n",
    "val_images_path = dataset1_path.joinpath('val_images')\n",
    "val_segmentation_path = dataset1_path.joinpath('val_segmentation')\n",
    "\n",
    "old_train_images_path = dataset1_path.joinpath('images_prepped_train')\n",
    "old_train_segmentation_path =dataset1_path.joinpath('annotations_prepped_train')\n",
    "\n",
    "old_val_images_path = dataset1_path.joinpath('images_prepped_test')\n",
    "old_val_segmentation_path = dataset1_path.joinpath('annotations_prepped_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dst, src in zip(\n",
    "    [train_images_path, train_segmentation_path, val_images_path,\n",
    "    val_segmentation_path],\n",
    "    [old_train_images_path, old_train_segmentation_path, old_val_images_path,\n",
    "    old_val_segmentation_path],\n",
    "):\n",
    "\n",
    "    try:\n",
    "        rename(src, dst)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "If you have less number of training pairs, the results might not be good be because the model might overfit. We can increase the size of the dataset by applying random transformations on the images. We can change the color properties like hue, saturation, brightness, etc of the input images. We can also apply transformations such as rotation, scale, and flipping. For the transformations which change the location of the pixels, the segmentation image should also be transformed the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example of image augmentation for segmentation](data:image/png;base64,)\n",
    "\n",
    "_Example of image augmentation for segmentation [Gupta (2019)](https://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html)_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update local folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no need to copy the remote files, as the remote repository does not exist or is empty.\n"
     ]
    }
   ],
   "source": [
    "update_from_remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update remote folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_notebook(to_remote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_to_remote()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('final_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb99caad2e6108abcca26e3b6f6ab0a4f5732dffcdf8db8d4482079102f9cf3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
